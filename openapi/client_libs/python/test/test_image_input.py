# coding: utf-8

"""
    EZ Diffusion API

    Simple API for creating AI-driven generative image and video.  This API provides image generation capabilities using diffusion models with support for: - Text-to-Image generation - Image-to-Image generation   - Inpainting - ControlNet - LoRA adapters for fine-tuned models - Multiple schedulers and configurations  The service runs on GPU-enabled infrastructure and returns high-quality generated images based on text prompts and optional control inputs. 

    The version of the OpenAPI document: 1.0.0
    Generated by OpenAPI Generator (https://openapi-generator.tech)

    Do not edit the class manually.
"""  # noqa: E501


import unittest

from ez_diffusion_client.models.image_input import ImageInput

class TestImageInput(unittest.TestCase):
    """ImageInput unit test stubs"""

    def setUp(self):
        pass

    def tearDown(self):
        pass

    def make_instance(self, include_optional) -> ImageInput:
        """Test ImageInput
            include_optional is a boolean, when False only required
            params are included, when True both required and
            optional params are included """
        # uncomment below to create an instance of `ImageInput`
        """
        model = ImageInput()
        if include_optional:
            return ImageInput(
                source = ''
            )
        else:
            return ImageInput(
                source = '',
        )
        """

    def testImageInput(self):
        """Test ImageInput"""
        # inst_req_only = self.make_instance(include_optional=False)
        # inst_req_and_optional = self.make_instance(include_optional=True)

if __name__ == '__main__':
    unittest.main()
