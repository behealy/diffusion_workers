# coding: utf-8

"""
    EZ Diffusion API

    Simple API for creating AI-driven generative image and video.  This API provides image generation capabilities using diffusion models with support for: - Text-to-Image generation - Image-to-Image generation   - Inpainting - ControlNet - LoRA adapters for fine-tuned models - Multiple schedulers and configurations  The service runs on GPU-enabled infrastructure and returns high-quality generated images based on text prompts and optional control inputs. 

    The version of the OpenAPI document: 1.0.0
    Generated by OpenAPI Generator (https://openapi-generator.tech)

    Do not edit the class manually.
"""  # noqa: E501


import unittest

from ez_diffusion_client.models.image_generate_request import ImageGenerateRequest

class TestImageGenerateRequest(unittest.TestCase):
    """ImageGenerateRequest unit test stubs"""

    def setUp(self):
        pass

    def tearDown(self):
        pass

    def make_instance(self, include_optional) -> ImageGenerateRequest:
        """Test ImageGenerateRequest
            include_optional is a boolean, when False only required
            params are included, when True both required and
            optional params are included """
        # uncomment below to create an instance of `ImageGenerateRequest`
        """
        model = ImageGenerateRequest()
        if include_optional:
            return ImageGenerateRequest(
                input = ez_diffusion_client.models.image_generation_params.ImageGenerationParams(
                    prompt = 'A beautiful landscape with mountains and lakes, highly detailed', 
                    starting_image = '', 
                    negative_prompt = 'blurry, low quality, distorted', 
                    base_model = 'stabilityai/stable-diffusion-xl-base-1.0', 
                    guidance_scale = 0.0, 
                    inference_steps = 1, 
                    seed = 56, 
                    dimensions = ez_diffusion_client.models.image_generation_params_dimensions.ImageGenerationParams_dimensions(
                        width = 56, 
                        height = 56, ), 
                    inpaint = ez_diffusion_client.models.inpaint_params.InpaintParams(
                        starting_image = ez_diffusion_client.models.image_input.ImageInput(
                            source = '', ), 
                        mask_image = ez_diffusion_client.models.image_input.ImageInput(
                            source = '', ), 
                        use_controlnet_union_inpaint = True, ), 
                    image_to_image = ez_diffusion_client.models.image_to_image_params.ImageToImageParams(
                        starting_image = , ), 
                    controlnets = [
                        ez_diffusion_client.models.control_net_params.ControlNetParams(
                            guess_mode = True, 
                            guide_image = , 
                            needs_preprocess = True, 
                            model = '', 
                            controlnet_conditioning_scale = 0.0, 
                            control_guidance_end = 0.0, 
                            control_guidance_start = 0.0, 
                            strength = 0.0, 
                            processor_type = 'canny', )
                        ], 
                    loras = [
                        ez_diffusion_client.models.lora_params.LoraParams(
                            model = 'author/anime-lora', 
                            weight_name = 'anime.safetensors', 
                            tag = 'anime style', 
                            scale = 1.337, )
                        ], 
                    pipeline_optimizations = ez_diffusion_client.models.image_generation_params_pipeline_optimizations.ImageGenerationParams_pipeline_optimizations(
                        use_deepcache = False, 
                        deepcache_interval = 3, 
                        deepcache_branch_id = 0, 
                        use_torch_compile = False, ), )
            )
        else:
            return ImageGenerateRequest(
                input = ez_diffusion_client.models.image_generation_params.ImageGenerationParams(
                    prompt = 'A beautiful landscape with mountains and lakes, highly detailed', 
                    starting_image = '', 
                    negative_prompt = 'blurry, low quality, distorted', 
                    base_model = 'stabilityai/stable-diffusion-xl-base-1.0', 
                    guidance_scale = 0.0, 
                    inference_steps = 1, 
                    seed = 56, 
                    dimensions = ez_diffusion_client.models.image_generation_params_dimensions.ImageGenerationParams_dimensions(
                        width = 56, 
                        height = 56, ), 
                    inpaint = ez_diffusion_client.models.inpaint_params.InpaintParams(
                        starting_image = ez_diffusion_client.models.image_input.ImageInput(
                            source = '', ), 
                        mask_image = ez_diffusion_client.models.image_input.ImageInput(
                            source = '', ), 
                        use_controlnet_union_inpaint = True, ), 
                    image_to_image = ez_diffusion_client.models.image_to_image_params.ImageToImageParams(
                        starting_image = , ), 
                    controlnets = [
                        ez_diffusion_client.models.control_net_params.ControlNetParams(
                            guess_mode = True, 
                            guide_image = , 
                            needs_preprocess = True, 
                            model = '', 
                            controlnet_conditioning_scale = 0.0, 
                            control_guidance_end = 0.0, 
                            control_guidance_start = 0.0, 
                            strength = 0.0, 
                            processor_type = 'canny', )
                        ], 
                    loras = [
                        ez_diffusion_client.models.lora_params.LoraParams(
                            model = 'author/anime-lora', 
                            weight_name = 'anime.safetensors', 
                            tag = 'anime style', 
                            scale = 1.337, )
                        ], 
                    pipeline_optimizations = ez_diffusion_client.models.image_generation_params_pipeline_optimizations.ImageGenerationParams_pipeline_optimizations(
                        use_deepcache = False, 
                        deepcache_interval = 3, 
                        deepcache_branch_id = 0, 
                        use_torch_compile = False, ), ),
        )
        """

    def testImageGenerateRequest(self):
        """Test ImageGenerateRequest"""
        # inst_req_only = self.make_instance(include_optional=False)
        # inst_req_and_optional = self.make_instance(include_optional=True)

if __name__ == '__main__':
    unittest.main()
