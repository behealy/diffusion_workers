# coding: utf-8

"""
    EZ Diffusion API

    Simple API for creating AI-driven generative image and video.  This API provides image generation capabilities using diffusion models with support for: - Text-to-Image generation - Image-to-Image generation   - Inpainting - ControlNet - LoRA adapters for fine-tuned models - Multiple schedulers and configurations  The service runs on GPU-enabled infrastructure and returns high-quality generated images based on text prompts and optional control inputs. 

    The version of the OpenAPI document: 1.0.0
    Generated by OpenAPI Generator (https://openapi-generator.tech)

    Do not edit the class manually.
"""  # noqa: E501


from __future__ import annotations
import pprint
import re  # noqa: F401
import json

from pydantic import BaseModel, ConfigDict, Field, StrictInt, StrictStr
from typing import Any, ClassVar, Dict, List, Optional, Union
from typing_extensions import Annotated
from ez_diffusion_client.models.control_net_params import ControlNetParams
from ez_diffusion_client.models.image_generation_params_dimensions import ImageGenerationParamsDimensions
from ez_diffusion_client.models.image_generation_params_pipeline_optimizations import ImageGenerationParamsPipelineOptimizations
from ez_diffusion_client.models.image_to_image_params import ImageToImageParams
from ez_diffusion_client.models.inpaint_params import InpaintParams
from ez_diffusion_client.models.lora_params import LoraParams
from typing import Optional, Set
from typing_extensions import Self

class ImageGenerationParams(BaseModel):
    """
    ImageGenerationParams
    """ # noqa: E501
    prompt: Annotated[str, Field(min_length=1, strict=True)] = Field(description="Text prompt describing the desired image")
    starting_image: Optional[StrictStr] = Field(default=None, description="Base64 encoded starting image for image-to-image or inpainting")
    negative_prompt: Optional[StrictStr] = Field(default=None, description="Negative prompt to avoid unwanted elements")
    base_model: Optional[StrictStr] = Field(default=None, description="HuggingFace model identifier to use for generation")
    guidance_scale: Optional[Union[Annotated[float, Field(le=20.0, strict=True, ge=0.0)], Annotated[int, Field(le=20, strict=True, ge=0)]]] = Field(default=7.5, description="How closely to follow the prompt (higher = more faithful)")
    inference_steps: Optional[Annotated[int, Field(le=100, strict=True, ge=1)]] = Field(default=50, description="Number of denoising steps (higher = more detailed but slower)")
    seed: Optional[StrictInt] = Field(default=None, description="Random seed for reproducible generation")
    dimensions: ImageGenerationParamsDimensions
    inpaint: Optional[InpaintParams] = None
    image_to_image: Optional[ImageToImageParams] = None
    controlnets: Optional[List[ControlNetParams]] = Field(default=None, description="List of ControlNet configurations")
    loras: Optional[List[LoraParams]] = Field(default=None, description="List of LoRA adapter configurations")
    pipeline_optimizations: Optional[ImageGenerationParamsPipelineOptimizations] = None
    __properties: ClassVar[List[str]] = ["prompt", "starting_image", "negative_prompt", "base_model", "guidance_scale", "inference_steps", "seed", "dimensions", "inpaint", "image_to_image", "controlnets", "loras", "pipeline_optimizations"]

    model_config = ConfigDict(
        populate_by_name=True,
        validate_assignment=True,
        protected_namespaces=(),
    )


    def to_str(self) -> str:
        """Returns the string representation of the model using alias"""
        return pprint.pformat(self.model_dump(by_alias=True))

    def to_json(self) -> str:
        """Returns the JSON representation of the model using alias"""
        # TODO: pydantic v2: use .model_dump_json(by_alias=True, exclude_unset=True) instead
        return json.dumps(self.to_dict())

    @classmethod
    def from_json(cls, json_str: str) -> Optional[Self]:
        """Create an instance of ImageGenerationParams from a JSON string"""
        return cls.from_dict(json.loads(json_str))

    def to_dict(self) -> Dict[str, Any]:
        """Return the dictionary representation of the model using alias.

        This has the following differences from calling pydantic's
        `self.model_dump(by_alias=True)`:

        * `None` is only added to the output dict for nullable fields that
          were set at model initialization. Other fields with value `None`
          are ignored.
        """
        excluded_fields: Set[str] = set([
        ])

        _dict = self.model_dump(
            by_alias=True,
            exclude=excluded_fields,
            exclude_none=True,
        )
        # override the default output from pydantic by calling `to_dict()` of dimensions
        if self.dimensions:
            _dict['dimensions'] = self.dimensions.to_dict()
        # override the default output from pydantic by calling `to_dict()` of inpaint
        if self.inpaint:
            _dict['inpaint'] = self.inpaint.to_dict()
        # override the default output from pydantic by calling `to_dict()` of image_to_image
        if self.image_to_image:
            _dict['image_to_image'] = self.image_to_image.to_dict()
        # override the default output from pydantic by calling `to_dict()` of each item in controlnets (list)
        _items = []
        if self.controlnets:
            for _item_controlnets in self.controlnets:
                if _item_controlnets:
                    _items.append(_item_controlnets.to_dict())
            _dict['controlnets'] = _items
        # override the default output from pydantic by calling `to_dict()` of each item in loras (list)
        _items = []
        if self.loras:
            for _item_loras in self.loras:
                if _item_loras:
                    _items.append(_item_loras.to_dict())
            _dict['loras'] = _items
        # override the default output from pydantic by calling `to_dict()` of pipeline_optimizations
        if self.pipeline_optimizations:
            _dict['pipeline_optimizations'] = self.pipeline_optimizations.to_dict()
        # set to None if starting_image (nullable) is None
        # and model_fields_set contains the field
        if self.starting_image is None and "starting_image" in self.model_fields_set:
            _dict['starting_image'] = None

        # set to None if negative_prompt (nullable) is None
        # and model_fields_set contains the field
        if self.negative_prompt is None and "negative_prompt" in self.model_fields_set:
            _dict['negative_prompt'] = None

        # set to None if base_model (nullable) is None
        # and model_fields_set contains the field
        if self.base_model is None and "base_model" in self.model_fields_set:
            _dict['base_model'] = None

        # set to None if guidance_scale (nullable) is None
        # and model_fields_set contains the field
        if self.guidance_scale is None and "guidance_scale" in self.model_fields_set:
            _dict['guidance_scale'] = None

        # set to None if inference_steps (nullable) is None
        # and model_fields_set contains the field
        if self.inference_steps is None and "inference_steps" in self.model_fields_set:
            _dict['inference_steps'] = None

        # set to None if seed (nullable) is None
        # and model_fields_set contains the field
        if self.seed is None and "seed" in self.model_fields_set:
            _dict['seed'] = None

        # set to None if controlnets (nullable) is None
        # and model_fields_set contains the field
        if self.controlnets is None and "controlnets" in self.model_fields_set:
            _dict['controlnets'] = None

        # set to None if loras (nullable) is None
        # and model_fields_set contains the field
        if self.loras is None and "loras" in self.model_fields_set:
            _dict['loras'] = None

        return _dict

    @classmethod
    def from_dict(cls, obj: Optional[Dict[str, Any]]) -> Optional[Self]:
        """Create an instance of ImageGenerationParams from a dict"""
        if obj is None:
            return None

        if not isinstance(obj, dict):
            return cls.model_validate(obj)

        _obj = cls.model_validate({
            "prompt": obj.get("prompt"),
            "starting_image": obj.get("starting_image"),
            "negative_prompt": obj.get("negative_prompt"),
            "base_model": obj.get("base_model"),
            "guidance_scale": obj.get("guidance_scale") if obj.get("guidance_scale") is not None else 7.5,
            "inference_steps": obj.get("inference_steps") if obj.get("inference_steps") is not None else 50,
            "seed": obj.get("seed"),
            "dimensions": ImageGenerationParamsDimensions.from_dict(obj["dimensions"]) if obj.get("dimensions") is not None else None,
            "inpaint": InpaintParams.from_dict(obj["inpaint"]) if obj.get("inpaint") is not None else None,
            "image_to_image": ImageToImageParams.from_dict(obj["image_to_image"]) if obj.get("image_to_image") is not None else None,
            "controlnets": [ControlNetParams.from_dict(_item) for _item in obj["controlnets"]] if obj.get("controlnets") is not None else None,
            "loras": [LoraParams.from_dict(_item) for _item in obj["loras"]] if obj.get("loras") is not None else None,
            "pipeline_optimizations": ImageGenerationParamsPipelineOptimizations.from_dict(obj["pipeline_optimizations"]) if obj.get("pipeline_optimizations") is not None else None
        })
        return _obj


